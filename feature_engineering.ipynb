{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load requirements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# df_Items = pd.read_csv('./data-readonly/items.csv')\n",
    "df_Items_categories = pd.read_csv('./data-readonly/item_categories.csv')\n",
    "df_Shops = pd.read_csv('./data-readonly/shops.csv')\n",
    "\n",
    "# item_name = df_Items.item_name.values\n",
    "# item_name = ' '.join(item_name)\n",
    "# strip = re.compile(r'[()\\'\\[\\]!*,/\\-+.«»:&\"]')\n",
    "# item_name = strip.sub(' ',item_name)\n",
    "# item_name = item_name.split(' ')\n",
    "# item_name_counter = Counter(item_name)\n",
    "# for name, _ in item_name_counter.most_common(101):\n",
    "#     if name:\n",
    "#         df_Items['BoW_{}'.format(name)] = df_Items['item_name'].str.count(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some features from shop_name\n",
    "shop_name = df_Shops.shop_name.values\n",
    "shop_name = ' '.join(shop_name)\n",
    "strip = re.compile(r'[()\\'\\[\\]!*,/\\-+.«»:&\"]')\n",
    "shop_name = strip.sub(' ',shop_name)\n",
    "shop_name = shop_name.split(' ')\n",
    "shop_name_counter = Counter(shop_name)\n",
    "for name, _ in shop_name_counter.most_common(21):\n",
    "    if name:\n",
    "        df_Shops['BoW_{}'.format(name)] = df_Shops['shop_name'].str.count(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some features from item_category_name\n",
    "item_category_name = df_Items_categories.item_category_name.values\n",
    "item_category_name = ' '.join(item_category_name)\n",
    "strip = re.compile(r'[()\\'\\[\\]!*,/\\-+.«»:&\"]')\n",
    "item_category_name = strip.sub(' ',item_category_name)\n",
    "item_category_name = item_category_name.split(' ')\n",
    "item_category_name_counter = Counter(item_category_name)\n",
    "for name, _ in item_category_name_counter.most_common(21):\n",
    "    if name:\n",
    "        df_Items_categories['BoW_{}'.format(name)] = df_Items_categories['item_category_name'].str.count(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save features\n",
    "\n",
    "df_Items_categories.drop(columns='item_category_name').to_hdf('./HDF/features.hdf', key='item_categories')\n",
    "df_Shops.drop(columns='shop_name').to_hdf('./HDF/features.hdf', key='shops')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tfid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "\n",
    "df_Items = pd.read_csv('./data-readonly/items.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(analyzer='word',\n",
    "                        stop_words=stopwords.words('russian'),\n",
    "                        token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b',\n",
    "                        max_features=100)\n",
    "\n",
    "df_Items['star_count'] = df_Items['item_name'].str.count('\\*')\n",
    "df_Items['item_name'] = df_Items['item_name'].str.replace('[\\(\\)\\*BD\\/\\!\\d+]','')\n",
    "df_Items['item_name'] = df_Items['item_name'].apply(lambda x: x.lower())\n",
    "tfidf_values = tfidf.fit_transform(df_Items['item_name'])\n",
    "df_Items = pd.concat([df_Items,pd.DataFrame(tfidf_values.toarray(),\n",
    "                                            columns=tfidf.get_feature_names())],axis=1)\n",
    "df_Items['Regional'] = (df_Items['item_name'].str.contains('регион')).astype('int')\n",
    "df_Items['BlueRay'] = (df_Items['item_name'].str.contains('BD')).astype('int')\n",
    "\n",
    "df_Items.drop(columns='item_name').to_hdf('./HDF/features.hdf', key='items')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Release date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load release date\n",
    "df_Release = pd.read_csv('items_with_release_date.csv')\n",
    "df_Release['release_date'] = pd.to_datetime(df_Release['release_date'], format='%Y-%m-%d')\n",
    "df_Release['release_date_block_num'] = df_Release['release_date'].map(lambda x: (x.year - 2013) * 12 + x.month -1 + x.day / 30)\n",
    "df_Release['release_date_block_num'] = df_Release['release_date_block_num'].clip(lower=-1)\n",
    "df_Release['release_date_block_num'].fillna(-999, inplace=True)\n",
    "df_Release[['item_id', 'release_date_block_num']].to_hdf('./HDF/features.hdf', key='release_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load trainning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_Train = pd.read_hdf('./HDF/All_train.hdf', key='train')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Set Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag features\n",
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "cols_to_rename = list(df_Train.columns.difference(index_cols))\n",
    "\n",
    "shift_range = [1, 2, 3, 4, 6, 12]\n",
    "\n",
    "for month_shift in shift_range:\n",
    "    train_shift = df_Train[index_cols + cols_to_rename].copy()\n",
    "\n",
    "    train_shift['date_block_num'] = train_shift['date_block_num'] + month_shift\n",
    "\n",
    "    foo = lambda x: '{}_lag_{}'.format(x, month_shift) if x in cols_to_rename else x\n",
    "    train_shift = train_shift.rename(columns=foo)\n",
    "\n",
    "    df_Train = pd.merge(df_Train, train_shift, on=index_cols, how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get national holidays from https://www.officeholidays.com/countries/russia/2013.php\n",
    "num_holidays = [6, 1, 1, 0, 5, 1, 0, 0, 0, 0, 1, 0, 6, 1, 1, 0, 3, 2, 0, 0, 0, 0, 2, 0, 7, 1, 1, 0, 4, 4, 0, 0, 0, 0, 1, 0]\n",
    "for i in range(len(num_holidays)):\n",
    "    df_Train.loc[df_Train['date_block_num'] == i, 'num_holidays'] = num_holidays[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item / shop / category mean encoding using Expanding mean scheme\n",
    "df_Items = pd.read_csv('./data-readonly/items.csv')\n",
    "global_mean = df_Train.target.mean()\n",
    "df_Train = df_Train.merge(df_Items[['item_id','item_category_id']], on='item_id')\n",
    "\n",
    "for id in ['item_id', 'shop_id', 'item_category_id']:\n",
    "    cumsum = df_Train.groupby(id)['target'].cumsum() - df_Train['target']\n",
    "    cumcount = df_Train.groupby(id)['target'].cumcount()\n",
    "\n",
    "    df_Train['{}_target_enc'.format(id)]= cumsum / cumcount\n",
    "    df_Train['{}_target_enc'.format(id)].fillna(global_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load features\n",
    "\n",
    "df_Items = pd.read_hdf('./HDF/features.hdf', key='items')\n",
    "df_Items_categories = pd.read_hdf('./HDF/features.hdf', key='item_categories')\n",
    "df_Shops = pd.read_hdf('./HDF/features.hdf', key='shops')\n",
    "df_Release = pd.read_hdf('./HDF/features.hdf', key='release_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train = df_Train[df_Train['date_block_num'] >= 12] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge features\n",
    "merge_list = [\n",
    "    (df_Items_categories, 'item_category_id'),\n",
    "    (df_Items, 'item_id'),\n",
    "    (df_Shops, 'shop_id'),    \n",
    "    (df_Release, 'item_id')\n",
    "]\n",
    "for df, id in merge_list:\n",
    "    df_Train = df_Train.merge(df, on=id)\n",
    "\n",
    "drop_col = ['target']\n",
    "df_Train.drop(columns=drop_col).to_hdf('./HDF/Train_with_features.hdf', key='train_x')\n",
    "df_Train.target.to_hdf('./HDF/Train_with_features.hdf', key='train_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
